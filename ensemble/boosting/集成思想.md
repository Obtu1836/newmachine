
#梯度下降式 思想 以损失函数 为1/2*(yp-y)**2的损失函数为例
以单个样本为例  gbdt用的都是回归树  不考虑学习率  学习率的作用是防止异常值以及降低单棵树的波动

预测初始值(yp)    标签(y)         diff
 25              30           25-30=-5
                             一棵树 x拟合（-5）
                                得到-4.5
                                更新初始值 25-（-4.5）=29.5 

随着迭代次数(n颗树 不断的 拟合残差 使初始值不断靠近标签) 